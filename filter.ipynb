{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6287c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 9564 rows\n",
      "koi_disposition value counts:\n",
      "koi_disposition\n",
      "FALSE POSITIVE    4839\n",
      "CONFIRMED         2746\n",
      "CANDIDATE         1979\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered dataset size: 7585 rows\n",
      "Rows removed: 1979\n",
      "\n",
      "Filtered data saved to 'data_without_candidates/Kepler Objects of Interest - Filtered.csv'\n"
     ]
    }
   ],
   "source": [
    "# keplar cleaning script\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Kepler dataset, skipping comment lines\n",
    "df = pd.read_csv(\"Kepler Objects of Interest.csv\", comment=\"#\")\n",
    "\n",
    "print(f\"Original dataset size: {len(df)} rows\")\n",
    "print(f\"koi_disposition value counts:\")\n",
    "print(df[\"koi_disposition\"].value_counts())\n",
    "\n",
    "# remove all candidate rows from koi_disposition\n",
    "df_filtered = df[df[\"koi_disposition\"] != \"CANDIDATE\"]\n",
    "\n",
    "KEPLAR_COLUMNS_TO_DROP = [\n",
    "    \"ra\",\n",
    "    \"koi_steff\",\n",
    "    \"koi_steff_err1\",\n",
    "    \"koi_steff_err2\",\n",
    "    \"koi_slogg\",\n",
    "    \"koi_slogg_err1\",\n",
    "    \"koi_slogg_err2\",\n",
    "    \"koi_srad_err1\",\n",
    "    \"koi_kepmag\",\n",
    "    \"koi_kepmag\",\n",
    "    \"koi_tce_plnt_num\",\n",
    "    \"koi_insol_err1\",\n",
    "    \"koi_insol_err2\",\n",
    "    \"koi_insol\",\n",
    "    \"koi_teq\",\n",
    "    \"koi_prad_err2\",\n",
    "    \"koi_prad_err1\",\n",
    "    \"koi_prad\",\n",
    "    \"koi_depth_err1\",\n",
    "    \"koi_duration_err2\",\n",
    "    \"koi_duration_err1\",\n",
    "    \"koi_impact_err2\",\n",
    "    \"koi_impact_err1\",\n",
    "    \"koi_time0bk_err2\",\n",
    "    \"koi_time0bk_err1\",\n",
    "    \"koi_time0bk\",\n",
    "    \"koi_period_err1\",\n",
    "    \"koi_period_err1\",\n",
    "]\n",
    "\n",
    "# drop koi_disposition column\n",
    "df_filtered = df_filtered.drop(\n",
    "    columns=[\"koi_pdisposition\", \"koi_teq_err1\", \"koi_teq_err2\"]\n",
    ")\n",
    "df_filtered = df_filtered.drop(\n",
    "    columns=[\"kepler_name\", \"kepid\", \"kepoi_name\", \"kepler_name\"]\n",
    ")\n",
    "df_filtered = df_filtered.drop(columns=[\"koi_tce_delivname\"])\n",
    "# if any of the columns in KEPLAR_COLUMNS_TO_DROP do not exist in df_filtered, ignore the error\n",
    "df_filtered = df_filtered.drop(columns=KEPLAR_COLUMNS_TO_DROP, errors='ignore')\n",
    "\n",
    "print(f\"\\nFiltered dataset size: {len(df_filtered)} rows\")\n",
    "print(f\"Rows removed: {len(df) - len(df_filtered)}\")\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"data_without_candidates/Kepler Objects of Interest - Filtered.csv\"\n",
    "df_filtered.to_csv(output_file, index=False)\n",
    "print(f\"\\nFiltered data saved to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ffdc380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 7703 rows\n",
      "tfopwg_disp value counts:\n",
      "tfopwg_disp\n",
      "PC     4679\n",
      "FP     1197\n",
      "CP      684\n",
      "KP      583\n",
      "APC     462\n",
      "FA       98\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered dataset size: 7241 rows\n",
      "Rows removed: 462\n",
      "\n",
      "Filtered data saved to 'data_without_candidates/TESS Objects of Interest - Filtered.csv'\n"
     ]
    }
   ],
   "source": [
    "# tess cleaning script\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the TESS dataset, skipping comment lines\n",
    "df = pd.read_csv('tess data.csv', comment='#')\n",
    "\n",
    "print(f\"Original dataset size: {len(df)} rows\")\n",
    "print(f\"tfopwg_disp value counts:\")\n",
    "print(df['tfopwg_disp'].value_counts())\n",
    "\n",
    "\n",
    "# ESS Follow-up Observing Program Working Group (TOPWG) Dispostion: APC=ambiguous planetary candidate CP=confirmed planet :O. FA=false alarm :O. FP=false positive KP=known planet :O. PC=planetary candidate :O. 08h08m42 77c -48/48m10 12c _4 406+0 \n",
    "\n",
    "# in tfopwg_disp, remove all PC, ie remove all candidates\n",
    "df_filtered = df[df['tfopwg_disp'] != 'PC']\n",
    "df_filtered = df[df['tfopwg_disp'] != 'APC']\n",
    "\n",
    "# drop tfopwg_disp column\n",
    "df_filtered = df_filtered.drop(columns=['toi', 'tid', 'pl_insolerr1', 'pl_insolerr2', 'pl_insollim', 'pl_eqterr1', 'pl_eqterr2', 'pl_eqtlim'])\n",
    "df_filtered = df_filtered.drop(columns=['rastr', 'decstr', 'toi_created', 'rowupdate'])\n",
    "\n",
    "print(f\"\\nFiltered dataset size: {len(df_filtered)} rows\")\n",
    "print(f\"Rows removed: {len(df) - len(df_filtered)}\")\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'data_without_candidates/TESS Objects of Interest - Filtered.csv'\n",
    "df_filtered.to_csv(output_file, index=False)\n",
    "print(f\"\\nFiltered data saved to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8384498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 4004 rows\n",
      "disposition value counts:\n",
      "disposition\n",
      "CONFIRMED         2315\n",
      "CANDIDATE         1374\n",
      "FALSE POSITIVE     293\n",
      "REFUTED             22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered dataset size: 2630 rows\n",
      "Rows removed: 1374\n",
      "\n",
      "Filtered data saved to 'data_without_candidates/K2 Planets and Candidates - Filtered.csv'\n"
     ]
    }
   ],
   "source": [
    "# k2 cleaning script\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the TESS dataset, skipping comment lines\n",
    "df = pd.read_csv('k2 planets and candidates.csv', comment='#')\n",
    "\n",
    "print(f\"Original dataset size: {len(df)} rows\")\n",
    "print(f\"disposition value counts:\")\n",
    "print(df['disposition'].value_counts())\n",
    "\n",
    "# remove all candidate rows from disposition\n",
    "df_filtered = df[df['disposition'] != 'CANDIDATE']\n",
    "# drop disposition column\n",
    "df_filtered = df_filtered.drop(columns=['pl_name', 'hostname', 'default_flag'])\n",
    "\n",
    "print(f\"\\nFiltered dataset size: {len(df_filtered)} rows\")\n",
    "print(f\"Rows removed: {len(df) - len(df_filtered)}\")\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'data_without_candidates/K2 Planets and Candidates - Filtered.csv'\n",
    "df_filtered.to_csv(output_file, index=False)\n",
    "print(f\"\\nFiltered data saved to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "woclwpn9ejo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 4004 rows\n",
      "Candidates dataset size: 1374 rows\n",
      "\n",
      "Candidates data saved to 'data_with_candidates/K2 Planets and Candidates - Candidates.csv'\n"
     ]
    }
   ],
   "source": [
    "# k2 candidates extraction\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the K2 dataset, skipping comment lines\n",
    "df = pd.read_csv('k2 planets and candidates.csv', comment='#')\n",
    "\n",
    "print(f\"Original dataset size: {len(df)} rows\")\n",
    "\n",
    "# keep only candidate rows from disposition\n",
    "df_candidates = df[df['disposition'] == 'CANDIDATE']\n",
    "# drop disposition column\n",
    "df_candidates = df_candidates.drop(columns=['pl_name', 'hostname', 'default_flag'])\n",
    "\n",
    "print(f\"Candidates dataset size: {len(df_candidates)} rows\")\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'data_with_candidates/K2 Planets and Candidates - Candidates.csv'\n",
    "df_candidates.to_csv(output_file, index=False)\n",
    "print(f\"\\nCandidates data saved to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "599hzuj5elx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 7703 rows\n",
      "Candidates dataset size: 5141 rows\n",
      "\n",
      "Candidates data saved to 'data_with_candidates/TESS Objects of Interest - Candidates.csv'\n"
     ]
    }
   ],
   "source": [
    "# tess candidates extraction\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the TESS dataset, skipping comment lines\n",
    "df = pd.read_csv('tess data.csv', comment='#')\n",
    "\n",
    "print(f\"Original dataset size: {len(df)} rows\")\n",
    "\n",
    "# in tfopwg_disp, keep only PC (planetary candidates) and APC (ambiguous planetary candidates)\n",
    "df_candidates = df[df['tfopwg_disp'].isin(['PC', 'APC'])]\n",
    "\n",
    "# drop tfopwg_disp column\n",
    "df_candidates = df_candidates.drop(columns=['toi', 'tid', ])\n",
    "df_candidates = df_candidates.drop(columns=['rastr', 'decstr', 'toi_created', 'rowupdate'])\n",
    "print(f\"Candidates dataset size: {len(df_candidates)} rows\")\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'data_with_candidates/TESS Objects of Interest - Candidates.csv'\n",
    "df_candidates.to_csv(output_file, index=False)\n",
    "print(f\"\\nCandidates data saved to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9lw6t17r0zf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 9564 rows\n",
      "Candidates dataset size: 1979 rows\n",
      "\n",
      "Candidates data saved to 'data_with_candidates/Kepler Objects of Interest - Candidates.csv'\n"
     ]
    }
   ],
   "source": [
    "# keplar candidates extraction\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Kepler dataset, skipping comment lines\n",
    "df = pd.read_csv('Kepler Objects of Interest.csv', comment='#')\n",
    "\n",
    "print(f\"Original dataset size: {len(df)} rows\")\n",
    "\n",
    "# keep only candidate rows from koi_disposition\n",
    "df_candidates = df[df['koi_disposition'] == 'CANDIDATE']\n",
    "# drop koi_disposition column\n",
    "# drop koi_disposition column\n",
    "df_candidates = df_candidates.drop(columns=['koi_pdisposition', 'koi_teq_err1', 'koi_teq_err2'])\n",
    "df_candidates = df_candidates.drop(columns=['kepler_name', 'kepid', 'kepoi_name', 'kepler_name'])\n",
    "df_candidates = df_candidates.drop(columns=['koi_tce_delivname'])\n",
    "\n",
    "print(f\"Candidates dataset size: {len(df_candidates)} rows\")\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'data_with_candidates/Kepler Objects of Interest - Candidates.csv'\n",
    "df_candidates.to_csv(output_file, index=False)\n",
    "print(f\"\\nCandidates data saved to '{output_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
